{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tool_evaluator_agent.tools import ScrapingFishTool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "SCRAPING_FISH_API_KEY = os.getenv(\"SCRAPING_FISH_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Tool: Scrape website content\n"
     ]
    }
   ],
   "source": [
    "content = ScrapingFishTool().run('https://www.orulo.com.br')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Google Gemini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aolchik/mambaforge/envs/crewai/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from google.oauth2 import service_account\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "# Set the path to the service account JSON key file\n",
    "service_account_file = os.getenv(\"GOOGLE_SERVICE_ACCOUNT_FILE\")\n",
    "\n",
    "# Authenticate using the service account key\n",
    "credentials = service_account.Credentials.from_service_account_file(service_account_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1724249811.931081 19971561 check_gcp_environment_no_op.cc:29] ALTS: Platforms other than Linux and Windows are not supported\n",
      "I0000 00:00:1724249811.931865 19971561 check_gcp_environment_no_op.cc:29] ALTS: Platforms other than Linux and Windows are not supported\n"
     ]
    }
   ],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "llm=ChatGoogleGenerativeAI(model='gemini-1.5-flash',\n",
    "                            verbose=True,\n",
    "                            temperature=0.5,\n",
    "                            credentials=credentials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_google_genai.chat_models.ChatGoogleGenerativeAI'>\n"
     ]
    }
   ],
   "source": [
    "print(type(llm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isinstance(llm, ChatGoogleGenerativeAI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gemini-1.5-flash'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.model.split('/')[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"(Verse 1)\\nIn the realm of code, where data flows,\\nA tool was born, LangChain, it goes.\\nWith chains of thought, it weaves its spell,\\nTo unlock knowledge, secrets to tell.\\n\\n(Chorus)\\nOh, LangChain, LangChain, a symphony of code,\\nConnecting minds, a path we've strode.\\nWith prompts and chains, we tap the well,\\nOf language models, stories to tell.\\n\\n(Verse 2)\\nFrom LLM's power, we draw our might,\\nTo answer questions, day and night.\\nWith prompts we guide, with chains we bind,\\nA tapestry of words, for all to find.\\n\\n(Chorus)\\nOh, LangChain, LangChain, a symphony of code,\\nConnecting minds, a path we've strode.\\nWith prompts and chains, we tap the well,\\nOf language models, stories to tell.\\n\\n(Verse 3)\\nThrough agents and tools, it takes its stand,\\nTo automate tasks, with a helping hand.\\nFrom summarization to text creation,\\nLangChain empowers, with innovation.\\n\\n(Chorus)\\nOh, LangChain, LangChain, a symphony of code,\\nConnecting minds, a path we've strode.\\nWith prompts and chains, we tap the well,\\nOf language models, stories to tell.\\n\\n(Outro)\\nSo let us sing, of LangChain's grace,\\nA tool for all, in every space.\\nWith chains of thought, it guides our way,\\nTo a future bright, where knowledge holds sway. \\n\", response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': [{'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HARASSMENT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'probability': 'NEGLIGIBLE', 'blocked': False}]}, id='run-470fd70c-d091-4c23-bf8b-7ac5564a1336-0', usage_metadata={'input_tokens': 8, 'output_tokens': 337, 'total_tokens': 345})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"Sing a ballad of LangChain.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "llm = ChatOpenAI(model='gpt-4o',\n",
    "                  verbose=True,\n",
    "                  temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?ChatOpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LiteLLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aolchik/mambaforge/envs/crewai/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from google.oauth2 import service_account\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "# Set the path to the service account JSON key file\n",
    "service_account_file = os.getenv(\"GOOGLE_SERVICE_ACCOUNT_FILE\")\n",
    "\n",
    "# Authenticate using the service account key\n",
    "credentials = service_account.Credentials.from_service_account_file(service_account_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_models import ChatLiteLLM\n",
    "chat = ChatLiteLLM(model=\"gpt-3.5-turbo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_community.chat_models.litellm.ChatLiteLLM"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(chat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat.model_name = chat.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gpt-3.5-turbo'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat.model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hasattr(chat, \"model_name\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms import Ollama\n",
    "\n",
    "llm = Ollama(model='invalid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLM Wrapper\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers.llm_wrapper import ModelParams\n",
    "\n",
    "p = ModelParams()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.use_cache"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Observability\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helicone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"model\": 'gpt-3.5-turbo',\n",
    "    \"temperature\": 0,\n",
    "    \"verbose\": True,\n",
    "}\n",
    "\n",
    "params[\"base_url\"] = \"https://oai.helicone.ai/v1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "headers = {\n",
    "    \"Helicone-Auth\": f\"Bearer {os.getenv('HELICONE_API_KEY')}\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Helicone-Auth': 'Bearer pk-helicone-itv4c7y-xxgecla-wegp4bq-ntrcs6a'}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "params[\"default_headers\"] = headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': 'gpt-3.5-turbo',\n",
       " 'temperature': 0,\n",
       " 'verbose': True,\n",
       " 'base_url': 'https://oai.helicone.ai/v1',\n",
       " 'default_headers': {'Helicone-Auth': 'Bearer pk-helicone-itv4c7y-xxgecla-wegp4bq-ntrcs6a'}}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "llm = ChatOpenAI(**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"In the land of LangChain, a tale unfolds\\nOf heroes and villains, of legends untold\\nA kingdom divided, by power and greed\\nBut a hero arises, to fulfill a great need\\n\\nLangChain, oh LangChain, a land of strife\\nWhere darkness and light, battle for life\\nBut in the shadows, a hero stands tall\\nTo bring peace and justice, to one and all\\n\\nWith sword in hand, and heart of gold\\nLangChain's hero, brave and bold\\nFights for the innocent, fights for the weak\\nTo bring an end, to the darkness that seeks\\n\\nThrough battles and trials, the hero prevails\\nWith courage and honor, their quest never fails\\nLangChain is saved, by their selfless deed\\nA legend forever, in LangChain's creed\\n\\nSo raise a toast, to LangChain's hero true\\nTheir story will live on, forever anew\\nIn the hearts of the people, their legend will reign\\nIn the land of LangChain, where heroes remain.\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 209, 'prompt_tokens': 15, 'total_tokens': 224}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-84916566-8c9a-4a8e-8034-d0bb7df2bef1-0', usage_metadata={'input_tokens': 15, 'output_tokens': 209, 'total_tokens': 224})"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"Sing a ballad of LangChain.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers.tracer import TracerFactory\n",
    "\n",
    "tracer = TracerFactory.get_tracer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers.tracer import TracerAnnotation\n",
    "tracer.provider = 'helicone'\n",
    "tracer.annotation = TracerAnnotation(app='tool_evaluator_agent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LLMProxyConfig(url='https://oai.helicone.ai/v1', headers={'Helicone-Auth': 'Bearer pk-helicone-itv4c7y-xxgecla-wegp4bq-ntrcs6a', 'Helicone-Cache-Enabled': 'true', 'Helicone-Property-Session': '45b4bdb6-4803-4de2-86e1-7776ebf05344', 'Helicone-Property-App': 'tool_evaluator_agent'})"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proxy_config = tracer.get_proxy_config()\n",
    "proxy_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': 'gpt-3.5-turbo',\n",
       " 'temperature': 0,\n",
       " 'verbose': True,\n",
       " 'base_url': 'https://oai.helicone.ai/v1',\n",
       " 'default_headers': {'Helicone-Auth': 'Bearer pk-helicone-itv4c7y-xxgecla-wegp4bq-ntrcs6a',\n",
       "  'Helicone-Cache-Enabled': 'true',\n",
       "  'Helicone-Property-Session': '45b4bdb6-4803-4de2-86e1-7776ebf05344',\n",
       "  'Helicone-Property-App': 'tool_evaluator_agent'}}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "params[\"base_url\"] = proxy_config.url\n",
    "params[\"default_headers\"] = proxy_config.headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'__main__'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "__name__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tracer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers.tracer import TracerFactory, TracerAnnotation\n",
    "tracer = TracerFactory.get_tracer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tracer(provider='helicone', annotation=None)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tracer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracer.provider = 'helicone'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tracer(provider='helicone', annotation=None)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tracer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LLMProxyConfig(url='https://oai.helicone.ai/v1', headers={'Helicone-Auth': 'Bearer pk-helicone-itv4c7y-xxgecla-wegp4bq-ntrcs6a', 'Helicone-Cache-Enabled': 'true'})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tracer.get_proxy_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger('tool-evaluator-agent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-26 10:46:44,684 - tool-evaluator-agent - DEBUG - Tracer ended with provider: Google\n"
     ]
    }
   ],
   "source": [
    "provider = \"Google\"\n",
    "logger.debug(f\"Tracer ended with provider: {provider}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure the root logger\n",
    "logging.basicConfig(\n",
    "    level=logging.DEBUG,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-26 10:47:51,295 - tool-evaluator-agent - DEBUG - Tracer ended with provider: Google\n"
     ]
    }
   ],
   "source": [
    "logger = logging.getLogger('tool-evaluator-agent')\n",
    "provider = \"Google\"\n",
    "logger.debug(f\"Tracer ended with provider: {provider}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create a common logger instance\n",
    "logger = logging.getLogger('tool-evaluator-agent')\n",
    "\n",
    "# Example: Adding a file handler\n",
    "file_handler = logging.FileHandler('logs/app-debug.log')\n",
    "file_handler.setLevel(logging.DEBUG)\n",
    "file_handler.setFormatter(\n",
    "    logging.Formatter('%(asctime)s - %(name)s - '\n",
    "                      '%(levelname)s - %(message)s'))\n",
    "logger.addHandler(file_handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-26 10:54:17,065 - tool-evaluator-agent - DEBUG - Tracer ended with provider: Google\n"
     ]
    }
   ],
   "source": [
    "logger = logging.getLogger('tool-evaluator-agent')\n",
    "provider = \"Google\"\n",
    "logger.debug(f\"Tracer ended with provider: {provider}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "logging.Logger"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Logger tool-evaluator-agent (DEBUG)>\n"
     ]
    }
   ],
   "source": [
    "print(logger)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "crewai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
