{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "import sys\n",
    "sys.path.append('./src')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Composio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from composio import Composio\n",
    "\n",
    "composio_client = Composio()\n",
    "\n",
    "entity = composio_client.get_entity()\n",
    "\n",
    "print(entity.get_connections())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "actions = composio_client.actions.get()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# filter elements of actions array where attribute name starts with 'GOOGLE \n",
    "google_actions = list(filter(lambda action: action.name.startswith('GOOGLEDOCS'), actions))\n",
    "\n",
    "\n",
    "# pretty print actions, ActionModel elements\n",
    "for action in google_actions:\n",
    "    print(action)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from composio_crewai import ComposioToolSet, Action\n",
    "from composio.utils import logging\n",
    "\n",
    "logging.setup(logging.LogLevel.DEBUG)\n",
    "tool_set = ComposioToolSet()\n",
    "tools = tool_set.get_tools(actions=[Action.GOOGLEDOCS_UPDATE_EXISTING_DOCUMENT, Action.GOOGLEDOCS_GET_DOCUMENT_BY_ID])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrapting Fish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents.tool_evaluator.tools import ScrapingFishTool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "SCRAPING_FISH_API_KEY = os.getenv(\"SCRAPING_FISH_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = ScrapingFishTool().run('https://www.orulo.com.br')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Google Gemini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from google.oauth2 import service_account\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "# Set the path to the service account JSON key file\n",
    "service_account_file = os.getenv(\"GOOGLE_SERVICE_ACCOUNT_FILE\")\n",
    "\n",
    "# Authenticate using the service account key\n",
    "credentials = service_account.Credentials.from_service_account_file(service_account_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "llm=ChatGoogleGenerativeAI(model='gemini-1.5-flash',\n",
    "                            verbose=True,\n",
    "                            temperature=0.5,\n",
    "                            credentials=credentials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(llm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isinstance(llm, ChatGoogleGenerativeAI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm.model.split('/')[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm.invoke(\"Sing a ballad of LangChain.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "llm = ChatOpenAI(model='gpt-4o',\n",
    "                  verbose=True,\n",
    "                  temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?ChatOpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LiteLLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from google.oauth2 import service_account\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "# Set the path to the service account JSON key file\n",
    "service_account_file = os.getenv(\"GOOGLE_SERVICE_ACCOUNT_FILE\")\n",
    "\n",
    "# Authenticate using the service account key\n",
    "credentials = service_account.Credentials.from_service_account_file(service_account_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_models import ChatLiteLLM\n",
    "chat = ChatLiteLLM(model=\"gpt-3.5-turbo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(chat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat.model_name = chat.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat.model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hasattr(chat, \"model_name\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms import Ollama\n",
    "\n",
    "llm = Ollama(model='invalid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLM Wrapper\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print current directory\n",
    "import os\n",
    "\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add ./src to python path\n",
    "import sys\n",
    "sys.path.append('./src')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers.llm_wrapper import ModelParams\n",
    "\n",
    "p = ModelParams()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.use_cache"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trulens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers.llm_wrapper import ModelParams\n",
    "\n",
    "p = ModelParams(use_trulens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.use_trulens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers.llm_wrapper import get_llm, get_model_name\n",
    "llm = get_llm('openai', 'gpt-3.5-turbo-1106', config=p)\n",
    "print(get_model_name(llm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Observability\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helicone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"model\": 'gpt-3.5-turbo',\n",
    "    \"temperature\": 0,\n",
    "    \"verbose\": True,\n",
    "}\n",
    "\n",
    "params[\"base_url\"] = \"https://oai.helicone.ai/v1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "headers = {\n",
    "    \"Helicone-Auth\": f\"Bearer {os.getenv('HELICONE_API_KEY')}\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "params[\"default_headers\"] = headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "llm = ChatOpenAI(**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm.invoke(\"Sing a ballad of LangChain.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers.tracer import TracerFactory\n",
    "\n",
    "tracer = TracerFactory.get_tracer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers.tracer import TracerAnnotation\n",
    "tracer.provider = 'helicone'\n",
    "tracer.annotation = TracerAnnotation(app='tool_evaluator_agent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proxy_config = tracer.get_proxy_config()\n",
    "proxy_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "params[\"base_url\"] = proxy_config.url\n",
    "params[\"default_headers\"] = proxy_config.headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "__name__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tracer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers.tracer import TracerFactory, TracerAnnotation\n",
    "tracer = TracerFactory.get_tracer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracer.provider = 'helicone'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracer.get_proxy_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger('tool-evaluator-agent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "provider = \"Google\"\n",
    "logger.debug(f\"Tracer ended with provider: {provider}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure the root logger\n",
    "logging.basicConfig(\n",
    "    level=logging.DEBUG,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger('tool-evaluator-agent')\n",
    "provider = \"Google\"\n",
    "logger.debug(f\"Tracer ended with provider: {provider}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create a common logger instance\n",
    "logger = logging.getLogger('tool-evaluator-agent')\n",
    "\n",
    "# Example: Adding a file handler\n",
    "file_handler = logging.FileHandler('logs/app-debug.log')\n",
    "file_handler.setLevel(logging.DEBUG)\n",
    "file_handler.setFormatter(\n",
    "    logging.Formatter('%(asctime)s - %(name)s - '\n",
    "                      '%(levelname)s - %(message)s'))\n",
    "logger.addHandler(file_handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger('tool-evaluator-agent')\n",
    "provider = \"Google\"\n",
    "logger.debug(f\"Tracer ended with provider: {provider}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(logger)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agents & Tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fedback Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from trulens.core import Feedback\n",
    "from trulens.providers.openai import OpenAI\n",
    "from trulens.providers.bedrock import Bedrock\n",
    "from trulens.providers.bedrock.endpoint import BedrockEndpoint\n",
    "#import boto3\n",
    "\n",
    "# Initialize provider class\n",
    "provider = OpenAI(model_engine='gpt-4o')\n",
    "\n",
    "# boto3_session = boto3.Session(profile_name='iaproject', region_name='us-west-2')\n",
    "# boto3_client = boto3_session.client('bedrock')\n",
    "# provider = Bedrock(model_id='anthropic.claude-3-opus-20240229-v1:0', client=boto3_client, region_name='us-west-2')\n",
    "\n",
    "# select context to be used in feedback. the location of context is app specific.\n",
    "# context = TruChain.select_context(rag_chain)\n",
    "\n",
    "# Define a groundedness feedback function\n",
    "# f_groundedness = (\n",
    "#     Feedback(\n",
    "#         provider.groundedness_measure_with_cot_reasons, name=\"Groundedness\"\n",
    "#     )\n",
    "#     .on(context.collect())  # collect context chunks into a list\n",
    "#     .on_output()\n",
    "# )\n",
    "\n",
    "# Question/answer relevance between overall question and answer.\n",
    "f_answer_relevance = Feedback(\n",
    "     provider.relevance_with_cot_reasons, name=\"Answer Relevance\"\n",
    ").on_input_output()\n",
    "\n",
    "# Context relevance between question and each context chunk.\n",
    "# f_context_relevance = (\n",
    "#     Feedback(\n",
    "#         provider.context_relevance_with_cot_reasons, name=\"Context Relevance\"\n",
    "#     )\n",
    "#     .on_input()\n",
    "#     .on(context)\n",
    "#     .aggregate(np.mean)\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boto3_session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "provider"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tracer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers.tracer import TracerFactory, TracerAnnotation\n",
    "tracer = TracerFactory.get_tracer()\n",
    "tracer.provider = 'helicone'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tool Evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents.tool_evaluator.crew import ToolEvalCrewFactory\n",
    "from agents.tool_evaluator.main import crew_inputs as te_crew_inputs\n",
    "from trulens.apps.langchain import TruChain\n",
    "from trulens.core import TruSession\n",
    "from trulens.apps.langchain import TruChain\n",
    "\n",
    "te_factory = ToolEvalCrewFactory()\n",
    "\n",
    "te_session = TruSession()\n",
    "#te_session.reset_database()\n",
    "\n",
    "te_crew = te_factory.crew(agents=[te_factory.researcher()], \n",
    "                          tasks=[te_factory.criteria_clarification_task()])\n",
    "\n",
    "te_true_app = TruChain(te_crew.agents[0],\n",
    "                       app_name=f\"researcher@criteria-clarification-task\",\n",
    "                       app_version=\"0.0.1\",\n",
    "                       feedbacks=[f_answer_relevance])\n",
    "\n",
    "tracer.annotation = TracerAnnotation(app=te_true_app.app_name)\n",
    "print(f\"Tracer annotation is {tracer.annotation}\")\n",
    "\n",
    "with te_true_app as te_recordings:    \n",
    "    tracer.init()\n",
    "    te_crew.kickoff(te_crew_inputs)\n",
    "    tracer.end()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tool_evaluator_agent.main import crew_inputs\n",
    "\n",
    "crew = factory.crew(agents=[factory.researcher()], tasks=[factory.research_task()])\n",
    "\n",
    "from trulens.apps.langchain import TruChain\n",
    "true_app = TruChain(crew.agents[0],\n",
    "                    app_name=f\"researcher@research-task\",\n",
    "                    app_version=\"0.0.1\",\n",
    "                    feedbacks=[f_answer_relevance])\n",
    "\n",
    "with true_app as recordings:    \n",
    "    crew.kickoff(crew_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "te_session.get_leaderboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trulens.dashboard.display import get_feedback_result\n",
    "\n",
    "te_last_record = te_recordings.records[-1]\n",
    "te_feedback_df = get_feedback_result(te_last_record, \"Answer Relevance\")\n",
    "\n",
    "\n",
    "# align text to the left and do not crop cell content\n",
    "te_feedback_df.head(1).T.style.set_properties(**{'text-align': 'left', 'white-space': 'pre-wrap'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "te_records, te_feedback = te_session.get_records_and_feedback()\n",
    "\n",
    "te_records.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "te_records.tail(1)['Answer Relevance_calls'].values[0][0]['args']['prompt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "provider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "te_records.tail(1)['Answer Relevance_calls'].values[0][0]['args']['prompt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "te_records.tail(1)['Answer Relevance_calls'].values[0][0]['args']['response']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "provider.relevance_with_cot_reasons(te_records.tail(1)['Answer Relevance_calls'].values[0][0]['args']['prompt'],\n",
    "                                    te_records.tail(1)['Answer Relevance_calls'].values[0][0]['args']['response'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_like = last_record.layout_calls_as_app()\n",
    "\n",
    "from ipytree import Node\n",
    "from ipytree import Tree\n",
    "\n",
    "\n",
    "def display_call_stack(data):\n",
    "    tree = Tree()\n",
    "    tree.add_node(Node(\"Record ID: {}\".format(data[\"record_id\"])))\n",
    "    tree.add_node(Node(\"App ID: {}\".format(data[\"app_id\"])))\n",
    "    tree.add_node(Node(\"Cost: {}\".format(data[\"cost\"])))\n",
    "    tree.add_node(Node(\"Performance: {}\".format(data[\"perf\"])))\n",
    "    tree.add_node(Node(\"Timestamp: {}\".format(data[\"ts\"])))\n",
    "    tree.add_node(Node(\"Tags: {}\".format(data[\"tags\"])))\n",
    "    tree.add_node(Node(\"Main Input: {}\".format(data[\"main_input\"])))\n",
    "    tree.add_node(Node(\"Main Output: {}\".format(data[\"main_output\"])))\n",
    "    tree.add_node(Node(\"Main Error: {}\".format(data[\"main_error\"])))\n",
    "\n",
    "    calls_node = Node(\"Calls\")\n",
    "    tree.add_node(calls_node)\n",
    "\n",
    "    for call in data[\"calls\"]:\n",
    "        call_node = Node(\"Call\")\n",
    "        calls_node.add_node(call_node)\n",
    "\n",
    "        for step in call[\"stack\"]:\n",
    "            step_node = Node(\"Step: {}\".format(step[\"path\"]))\n",
    "            call_node.add_node(step_node)\n",
    "            if \"expanded\" in step:\n",
    "                expanded_node = Node(\"Expanded\")\n",
    "                step_node.add_node(expanded_node)\n",
    "                for expanded_step in step[\"expanded\"]:\n",
    "                    expanded_step_node = Node(\n",
    "                        \"Step: {}\".format(expanded_step[\"path\"])\n",
    "                    )\n",
    "                    expanded_node.add_node(expanded_step_node)\n",
    "\n",
    "    return tree\n",
    "\n",
    "\n",
    "# Usage\n",
    "tree = display_call_stack(json_like)\n",
    "tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trulens.dashboard import run_dashboard\n",
    "\n",
    "run_dashboard(te_session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trulens.dashboard import run_dashboard\n",
    "\n",
    "run_dashboard(te_session)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Formulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents.feature_formulator.crew import FeatureFormulatorCrewFactory\n",
    "from agents.feature_formulator.main import crew_inputs as ff_crew_inputs\n",
    "from trulens.apps.langchain import TruChain\n",
    "from trulens.core import TruSession\n",
    "from trulens.apps.langchain import TruChain\n",
    "\n",
    "\n",
    "ff_factory = FeatureFormulatorCrewFactory()\n",
    "\n",
    "ff_session = TruSession()\n",
    "#ff_session.reset_database()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ff_crew = ff_factory.crew(agents=[ff_factory.product_owner()], \n",
    "                          tasks=[ff_factory.feature_specification_task()])\n",
    "\n",
    "ff_true_app = TruChain(ff_crew.agents[0],\n",
    "                       app_name=f\"product_owner@feature_specification_task\",\n",
    "                       app_version=\"0.0.1\",\n",
    "                       feedbacks=[f_answer_relevance])\n",
    "\n",
    "tracer.annotation = TracerAnnotation(app=ff_true_app.app_name)\n",
    "print(f\"Tracer annotation is {tracer.annotation}\")\n",
    "\n",
    "with ff_true_app as ff_recordings:    \n",
    "    tracer.init()\n",
    "    ff_crew.kickoff(ff_crew_inputs)\n",
    "    tracer.end()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ff_crew = ff_factory.crew(agents=[ff_factory.product_owner()], \n",
    "                          tasks=[ff_factory.previous_spec_review_task()])\n",
    "\n",
    "ff_true_app = TruChain(ff_crew.agents[0],\n",
    "                       app_name=f\"teste\",\n",
    "                       app_version=\"0.0.1\",\n",
    "                       feedbacks=[f_answer_relevance])\n",
    "\n",
    "tracer.annotation = TracerAnnotation(app=ff_true_app.app_name)\n",
    "print(f\"Tracer annotation is {tracer.annotation}\")\n",
    "\n",
    "with ff_true_app as ff_recordings:    \n",
    "    tracer.init()\n",
    "    ff_crew.kickoff(ff_crew_inputs)\n",
    "    tracer.end()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trulens.dashboard import run_dashboard\n",
    "\n",
    "run_dashboard(ff_session)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "crewai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
